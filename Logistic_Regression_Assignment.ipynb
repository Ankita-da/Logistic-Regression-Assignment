{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankita-da/Logistic-Regression-Assignment/blob/main/Logistic_Regression_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exCn8mlCxz4f"
      },
      "outputs": [],
      "source": [
        "### Theoretical\n",
        "\n",
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Answer: Logistic Regression is used for classification tasks (predicting categories like yes/no), while Linear Regression is used for regression (predicting continuous values). Logistic Regression predicts probabilities using a sigmoid function, while Linear Regression predicts real-valued outputs.\n",
        "\n",
        "2. What is the mathematical equation of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "The general equation is:\n",
        "P(Y=1 | X) = 1 / (1 + exp(-(β₀ + β₁X₁ + β₂X₂ + ... + βnXn)) )\n",
        "Where:\n",
        "P(Y=1 | X): is the probability of Y=1 (the event of interest) given the input features X.\n",
        "β₀, β₁, β₂, ..., βn: are the coefficients or weights associated with each input feature X₁, X₂, ..., Xn.\n",
        "X₁, X₂, ..., Xn: are the input features or independent variables.\n",
        "exp(): is the exponential function (e^x).\n",
        "\n",
        "3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        "Answer: The sigmoid function maps any real-valued number into a range between 0 and 1, making it suitable for predicting probabilities.\n",
        "\n",
        "4. What is the cost function of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "Formula:\n",
        "The Log Loss for a single data point (x, y) is:\n",
        "-y * log(h(x)) - (1 - y) * log(1 - h(x))\n",
        "Where:\n",
        "y is the actual class label (0 or 1)\n",
        "h(x) is the predicted probability (output of the sigmoid function)\n",
        "\n",
        "\n",
        "5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        "Answer: Regularization adds a penalty to the cost function to prevent overfitting. It helps the model generalize better to new data.\n",
        "\n",
        "\n",
        "6. Explain the difference between Lasso, Ridge, and Elastic Net regression.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Lasso (L1): Shrinks some coefficients to zero (feature selection).\n",
        "\n",
        "Ridge (L2): Shrinks coefficients smoothly but none become exactly zero.\n",
        "\n",
        "Elastic Net: Combines L1 and L2, balancing sparsity and stability.\n",
        "\n",
        "\n",
        "\n",
        "7. When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        "Answer: Use Elastic Net when you have many correlated features and want both feature selection and model stability.\n",
        "\n",
        "\n",
        "8. What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "\n",
        "Answer: Higher λ increases regularization strength, reducing overfitting but may underfit if too high. Lower λ reduces regularization, risking overfitting.\n",
        "\n",
        "\n",
        "\n",
        "9. What are the key assumptions of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "The outcome is binary (or multinomial with extensions).\n",
        "\n",
        "Linear relationship between independent variables and log-odds.\n",
        "\n",
        "No multicollinearity among predictors.\n",
        "\n",
        "Independence of observations.\n",
        "\n",
        "Large sample size for stable estimates.\n",
        "\n",
        "\n",
        "\n",
        "10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Decision Trees\n",
        "\n",
        "Random Forests\n",
        "\n",
        "Support Vector Machines (SVM)\n",
        "\n",
        "k-Nearest Neighbors (k-NN)\n",
        "\n",
        "Naive Bayes\n",
        "\n",
        "Neural Networks\n",
        "\n",
        "\n",
        "\n",
        "11. What are Classification Evaluation Metrics?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision\n",
        "\n",
        "Recall\n",
        "\n",
        "F1-Score\n",
        "\n",
        "ROC-AUC\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "\n",
        "12. How does class imbalance affect Logistic Regression?\n",
        "\n",
        "Answer: It can cause the model to favor the majority class, leading to misleading accuracy. Metrics like precision, recall, and F1-score are better in such cases.\n",
        "\n",
        "\n",
        "13. What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        "Answer: It involves selecting the best model parameters (like regularization strength, type of penalty, solver) using techniques like grid search or cross-validation.\n",
        "\n",
        "\n",
        "14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        "Answer:\n",
        "\n",
        "liblinear: Good for small datasets, supports L1.\n",
        "\n",
        "saga: Good for large datasets, supports L1 and Elastic Net.\n",
        "\n",
        "lbfgs: Fast for L2 penalty, best for multiclass.\n",
        "\n",
        "Choose based on dataset size and regularization type.\n",
        "\n",
        "\n",
        "\n",
        "15. How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        "Answer:\n",
        "\n",
        "One-vs-Rest (OvR): One classifier per class.\n",
        "\n",
        "Multinomial (Softmax Regression): Single model predicting probabilities across classes.\n",
        "\n",
        "\n",
        "\n",
        "16. What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "Advantages:\n",
        "\n",
        "Simple and easy to implement\n",
        "\n",
        "Works well with linearly separable data\n",
        "\n",
        "Provides probabilities\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Assumes linearity in log-odds\n",
        "\n",
        "Struggles with non-linear relationships\n",
        "\n",
        "Sensitive to outliers and irrelevant features\n",
        "\n",
        "\n",
        "\n",
        "17. What are some use cases of Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Email spam detection\n",
        "\n",
        "Disease diagnosis\n",
        "\n",
        "Credit scoring\n",
        "\n",
        "Customer churn prediction\n",
        "\n",
        "Click-through rate prediction\n",
        "\n",
        "\n",
        "\n",
        "18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Logistic Regression: Binary classification.\n",
        "\n",
        "Softmax Regression: Generalization to multiclass classification by using softmax instead of sigmoid.\n",
        "\n",
        "\n",
        "19. How do we choose between One-vs-Rest (OvR) and Softmax for multiclass classification?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Use OvR for simplicity or when classes are imbalanced.\n",
        "\n",
        "Use Softmax for direct multiclass probability estimates and when using solvers that support it.\n",
        "\n",
        "\n",
        "20. How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        "Answer:\n",
        "Each coefficient represents the change in log-odds of the outcome for a one-unit increase in the predictor, holding others constant. Exponentiating the coefficient gives the odds ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQYgQIi-yHNo",
        "outputId": "8180b216-6b82-4c45-c36c-f775d23b1d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9737\n"
          ]
        }
      ],
      "source": [
        "#1. Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic Regression, and prints the model accuracy\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load sample dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Fit logistic regression with increased max_iter\n",
        "model = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ww9arB8zrB6",
        "outputId": "52641090-1717-4ca2-c048-27eb5e216d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Regularization Accuracy: 0.9561\n"
          ]
        }
      ],
      "source": [
        "#2. Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1') and print the model accuracy\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"L1 Regularization Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_yIOw4zu1I",
        "outputId": "ce235ec4-6f32-4c13-f04e-f5c5aca22607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Regularization Accuracy: 0.9737\n",
            "Coefficients: [[-0.43190368 -0.38732553 -0.39343248 -0.46521006 -0.07166728  0.54016395\n",
            "  -0.8014581  -1.11980408  0.23611852  0.07592093 -1.26817815  0.18887738\n",
            "  -0.61058302 -0.9071857  -0.31330675  0.68249145  0.17527452 -0.3112999\n",
            "   0.50042502  0.61622993 -0.87984024 -1.35060559 -0.58945273 -0.84184594\n",
            "  -0.54416967  0.01611019 -0.94305313 -0.77821726 -1.20820031 -0.15741387]]\n"
          ]
        }
      ],
      "source": [
        "# 3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using LogisticRegression(penalty='l2'). Print model accuracy and coefficients\n",
        "\n",
        "# Load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression with L2 regularization\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Output accuracy and coefficients\n",
        "print(f\"L2 Regularization Accuracy: {model.score(X_test_scaled, y_test):.4f}\")\n",
        "print(\"Coefficients:\", model.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLI9ybXLzwGp",
        "outputId": "b40ab042-1fd6-46c1-992d-2c4f1f858393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Accuracy: 0.9737\n"
          ]
        }
      ],
      "source": [
        "# 4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Elastic Net Logistic Regression\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',        # required for elasticnet\n",
        "    l1_ratio=0.5,         # mix of L1 and L2\n",
        "    C=1.0,\n",
        "    max_iter=2000,        # increased from 1000\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(f\"Elastic Net Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbhKfj4vzyRM",
        "outputId": "e537fc02-909c-42ad-95d0-afba86e71b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass OvR Accuracy: 0.9667\n"
          ]
        }
      ],
      "source": [
        "# 5. Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr'\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-vs-Rest Logistic Regression\n",
        "base_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "model = OneVsRestClassifier(base_model)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Multiclass OvR Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3CoaL9sz22o",
        "outputId": "5b02bf90-b4b4-4944-b555-f0f242497156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy: 0.9583\n"
          ]
        }
      ],
      "source": [
        "# 6. Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic Regression. Print the best parameters and accuracy\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {grid.best_params_}\")\n",
        "print(f\"Best Accuracy: {grid.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka1b2MHWz2md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11cda76-37b0-48be-d053-32ef569a7db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Stratified K-Fold Accuracy: 0.9667\n"
          ]
        }
      ],
      "source": [
        "# 7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the average accuracy\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "print(f\"Average Stratified K-Fold Accuracy: {scores.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "uewvKdfhz6SU",
        "outputId": "3bf880d2-a7dc-4ca0-efd8-894cfaf0ad4d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa26bf24-a527-4cd1-a9c7-d2767c148263\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa26bf24-a527-4cd1-a9c7-d2767c148263\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klNK7E4vz6PW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "542cdda8-849a-47f2-d128-06856134a08d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Name', 'Doctor', 'Gender', 'Date of Admission', 'Discharge Date', 'Insurance Provider'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ddc9946a0fc6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Drop irrelevant or non-numeric columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Doctor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gender'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Date of Admission'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Discharge Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Insurance Provider'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Name', 'Doctor', 'Gender', 'Date of Admission', 'Discharge Date', 'Insurance Provider'] not found in axis\""
          ]
        }
      ],
      "source": [
        "#8. Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its accuracy\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load CSV\n",
        "\n",
        "# Convert Medical Expenses into binary classification target\n",
        "\n",
        "df['High Expense'] = (df['Billing Amount'] > df['Billing Amount'].median()).astype(int)\n",
        "target_col = 'High Expense'\n",
        "\n",
        "# Drop irrelevant or non-numeric columns\n",
        "df = df.drop(['Name', 'Doctor', 'Gender', 'Date of Admission', 'Discharge Date','Insurance Provider'], axis=1)\n",
        "\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(target_col, axis=1)\n",
        "y = df[target_col]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = model.score(X_test_scaled, y_test)\n",
        "print(f\"CSV Dataset Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8-opV1Zz6L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5b9c72-c11a-4d04-8fa3-0705a36cbf9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': np.float64(10.0)}\n",
            "Best Accuracy: 0.9583\n"
          ]
        }
      ],
      "source": [
        "# 9. Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in Logistic Regression. Print the best parameters and accuracy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "# Optional: Suppress convergence warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define parameter grid\n",
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 10),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Logistic Regression with high iteration limit\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "\n",
        "# RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit model\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Output results\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(f\"Best Accuracy: {random_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78wfGYiMz6Iq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "3a0d9231-b015-4dad-85be-2e56e1ccd5e6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'A-'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d35cbdb67e73>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0movo_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsOneClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0movo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"OvO Accuracy: {ovo_model.score(X_test, y_test):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;31m# We need to validate the data because we do a safe_indexing later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m    800\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'A-'"
          ]
        }
      ],
      "source": [
        "# 10. Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy\n",
        "\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"OvO Accuracy: {ovo_model.score(X_test, y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65q3kjjVz6FH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "4c03a579-53e7-465c-81be-e1f1646effe2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'A-'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0ffae764c3d8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m   1223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'A-'"
          ]
        }
      ],
      "source": [
        "# 11. Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary classification\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2vP1bsUz6B5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "7290a65c-9274-479e-f28e-d3fa5e9f4c4b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'AB+'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a47b9505c4ba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \"\"\"\n\u001b[1;32m    373\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         return (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'AB+'"
          ]
        }
      ],
      "source": [
        "# 12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision, Recall, and F1-Score\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te71d4lQz5-u"
      },
      "outputs": [],
      "source": [
        "#13. Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to improve model performance\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Balanced Accuracy: {model.score(X_test, y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxtoYQL-z57x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345c9b17-85c6-443c-f0f6-c75297fab53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Titanic Dataset Accuracy: 0.7902\n"
          ]
        }
      ],
      "source": [
        "#14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and evaluate performance\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "titanic = sns.load_dataset('titanic').dropna(subset=['age', 'embarked', 'sex', 'fare', 'pclass', 'survived'])\n",
        "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
        "titanic['embarked'] = titanic['embarked'].astype('category').cat.codes\n",
        "\n",
        "X = titanic[['age', 'fare', 'pclass', 'sex', 'embarked']]\n",
        "y = titanic['survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Titanic Dataset Accuracy: {model.score(X_test, y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdY_CvSyz54l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464901e9-2feb-48f2-9330-69c3d50ad244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With Scaling: 0.7902\n",
            "Without Scaling: 0.7902\n"
          ]
        }
      ],
      "source": [
        "# 15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression model. Evaluate its accuracy and compare results with and without scaling\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train_s, X_test_s, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_s, y_train)\n",
        "\n",
        "model_unscaled = LogisticRegression(max_iter=1000)\n",
        "model_unscaled.fit(X_train, y_train)\n",
        "\n",
        "print(f\"With Scaling: {model_scaled.score(X_test_s, y_test):.4f}\")\n",
        "print(f\"Without Scaling: {model_unscaled.score(X_test, y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ7Syb6Nz51n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c13080-10bf-4c54-93f5-161ab742bcdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.8176587301587303\n"
          ]
        }
      ],
      "source": [
        "# 16. Write a Python program to train Logistic Regression and evaluate its performance using ROC-AUC score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyxFJzSzz5yV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5243c2-a00d-4d80-bc88-4a86c24e1946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom C=0.5 Accuracy: 0.7972\n"
          ]
        }
      ],
      "source": [
        "# 17. Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate accuracy\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Custom C=0.5 Accuracy: {model.score(X_test, y_test):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkosUUsez5ve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b67705b-11b3-424b-a5bc-d5cd28e8daad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex: 2.3640\n",
            "pclass: 1.2727\n",
            "embarked: 0.1439\n",
            "age: 0.0301\n",
            "fare: 0.0020\n"
          ]
        }
      ],
      "source": [
        "# 18. Write a Python program to train Logistic Regression and identify important features based on model coefficients\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "importance = np.abs(model.coef_[0])\n",
        "feature_names = X.columns\n",
        "\n",
        "for name, coef in sorted(zip(feature_names, importance), key=lambda x: -x[1]):\n",
        "    print(f\"{name}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LU5SUuClz5sK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea4ad90-53c1-4c41-d2ba-1363772d7dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 0.5764477581452354\n"
          ]
        }
      ],
      "source": [
        "# 19. Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa Score\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Cohen's Kappa Score:\", cohen_kappa_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0egO1_YXz5oz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "bfd82e76-7b22-4a33-c82b-d14ac5b18f5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7b27e989f550>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary classification\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBTZEoVlz5lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5c94f9-81e1-4f40-bfc8-f68dd3de03de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver: liblinear, Accuracy: 0.7832\n",
            "Solver: saga, Accuracy: 0.6643\n",
            "Solver: lbfgs, Accuracy: 0.7902\n"
          ]
        }
      ],
      "source": [
        "# 21. Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare their accuracy\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(f\"Solver: {solver}, Accuracy: {model.score(X_test, y_test):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAzSeLLitwaRb1L97U1paq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}